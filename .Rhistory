#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
# build site
usethis::use_pkgdown()
pkgdown::build_site()
#
# Étape 5: Hébergez le site Web à l'aide de pages GitHub
# ======================================================
# Ajouter _pkgdown.yml à Rbuildignore
usethis::use_build_ignore(files = "_pkgdown.yml")
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
# build site
usethis::use_pkgdown()
pkgdown::build_site()
getwd()
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(stringi)
#collect rubrique url
url_rubrique <- read_html("https://www.lesechos.ml/") %>%
html_nodes("#header-layout2 .container #dropdown ul li a") %>%
html_attr("href") %>% str_trim() %>% .[-1]
url_rubrique
# Collect pagination by rubrique
url_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(
url_pag=try(read_html(x) %>%
html_nodes(".pagination li a") %>%
html_attr("href") %>% str_trim()))})
url_pag
url_rubrique
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(stringi)
#collect rubrique url
url_rubrique <- read_html("https://www.lesechos.ml/") %>%
html_nodes("#header-layout2 .container #dropdown ul li a") %>%
html_attr("href") %>% str_trim() %>% .[-1]
url_rubrique
# Collect pagination by rubrique
url_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(
url_pag=try(read_html(x) %>%
html_nodes(".pagination li a") %>%
html_attr("href") %>% str_trim()))})
url_rubrique
# Collect pagination by rubrique
url_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(
url_pag = try(read_html(x) %>%
html_nodes("#wrapper .pagination li a") %>%
html_attr("href") %>% str_trim()))})
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(stringi)
#collect rubrique url
url_rubrique <- read_html("https://www.lesechos.ml/") %>%
html_nodes("#header-layout2 .container #dropdown ul li a") %>%
html_attr("href") %>% str_trim() %>% .[-1]
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(stringi)
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li a ul li a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li ul li a") %>%
html_attr("href")
?nodes
?html_nodes
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:last-child) ul li a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-menu ul li a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:nth-child(1)) a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href")
read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href") %>% str_trim()%>%
str_subset("^https://www.journaldumali.com/category/")
#collect rubrique url
url_rubrique <- read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href") %>% str_trim()%>%
str_subset("^https://www.journaldumali.com/category/")
url_rubrique <- read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href") %>% str_trim()
url_rubrique
#collect rubrique url
url_rubrique <- read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li a") %>%
html_attr("href") %>% str_trim()
url_rubrique
#collect rubrique url
url_rubrique <- read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href") %>% str_trim()
x = "https://www.journaldumali.com/category/economie/actualites-economie/"
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/")
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2] %>% as.integer()
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]]
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2]
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2] %>%
str_split("/") %>% .[[1]]
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2] %>%
str_split("/") %>% .[[1]] %>% .[1] %>% as.integer(
)
#collect rubrique url
url_rubrique <- read_html("https://www.journaldumali.com/") %>%
html_nodes(".wrapper header nav .container ul li:not(:nth-child(10)) .sub-category-menu li:not(:first-child) a") %>%
html_attr("href") %>% str_trim()
# Collect pagination by rubrique
number_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(url = x,
nbr_pg=tryCatch(
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2] %>%
str_split("/") %>% .[[1]] %>% .[1] %>% as.integer(),
error = function(e){NA},
warning=  function(e){NA}))})
# Collect pagination by rubrique
number_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(url = x,
nbr_pg=tryCatch(
read_html(x) %>%
html_node(".wrapper .main .wp-pagenavi .last") %>%
html_attr("href")  %>% str_split("page/") %>% .[[1]] %>% .[2] %>%
str_split("/") %>% .[[1]] %>% .[1] %>% as.integer(),
error = function(e){NA},
warning=  function(e){NA}))})
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
#collect rubrique url
url_rubrique <- read_html("https://www.lesechos.ml/") %>%
html_nodes("#header-layout2 .container #dropdown ul li a") %>%
html_attr("href") %>% str_trim() %>% .[-1]
# Collect pagination by rubrique
url_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(
url_pag = try(
read_html(x) %>%
html_nodes("#wrapper .pagination li a") %>%
html_attr("href") %>% str_trim()))})
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
# build site
usethis::use_pkgdown()
pkgdown::build_site()
library(xml2)
library(rvest)
library(tidyverse)
library(lubridate)
library(stringi)
#collect rubrique url
url_rubrique <- read_html("https://leprogresinfo.net/") %>%
html_nodes("#td-outer-wrap #td-header-menu ul li a") %>%
html_attr("href") %>% str_trim() %>% .[-c(1,8)]
#Pagination collect
number_pag <- map_dfr(.x = url_rubrique,
.f = function(x){
tibble(url = x,
nbr_pg=read_html(x) %>%
html_nodes("#td-outer-wrap .td-ss-main-content .page-nav .last") %>%
html_text() %>% as.integer())})
# Build all url
number_pag <- na.omit(number_pag)
number_pag_order <- number_pag %>%
split(1:nrow(.)) %>%
map_dfr(.f = function(x){
tibble(url = x$url,
nbr_pg=1:x$nbr_pg)})
number_pag_order <- number_pag_order[order(number_pag_order$nbr_pg),]
url_pag_leprogres<- paste0(number_pag_order$url,'page/', number_pag_order$nbr_pg, "/")
i = 1
x <- url_pag_leprogres[i]
date_article = try(read_html(x) %>%
html_nodes("#td-outer-wrap .td-ss-main-content .td-module-meta-info .td-post-date time") %>%
html_text() %>% str_trim() %>% dmy()%>% date())
date_article
date_article = try(read_html(x) %>%
html_nodes("#td-outer-wrap .td-ss-main-content .td-module-meta-info .td-post-date time") %>%
html_text() %>% str_trim())
date_article
# category url collecte
url_category <- read_html("https://lanationbenin.info/")%>%
html_nodes(".tz-header .tz-header-menu nav .menu-menu-principal-container ul li a") %>%
html_attr("href") %>% str_trim()  %>% .[c(2:6,8:13)]
# Collect pagination by rubrique
number_pag <- map_dfr(.x = url_category,
.f = function(x){
tibble(url = x,
nbr_pg=tryCatch(
read_html(x) %>%
html_nodes(".container #content ul li") %>%
html_text() %>% tail(2) %>% head(1) %>% as.integer(),
error = function(e){NA},
warning=  function(e){NA}))})
# Build all url
number_pag <- na.omit(number_pag)
number_pag_order <- number_pag %>%
split(1:nrow(.)) %>%
map_dfr(.f = function(x){
tibble(url = x$url,
nbr_pg=sort(1:x$nbr_pg))})
number_pag_order <- number_pag_order[order(number_pag_order$nbr_pg),]
url_pag_lanationbenin <- paste0(number_pag_order$url,'page/', number_pag_order$nbr_pg, "/")
xx <- url_pag_lanationbenin[i]
xx
date_article = try(
read_html(xx) %>%
html_nodes(".container #content article header time") %>%
html_text() %>% dmy() %>% date())
date_article
date_article = try(
read_html(x) %>%
html_nodes(".container #content article header time") %>%
html_text())
date_article
date_article = try(
read_html(xx) %>%
html_nodes(".container #content article header time") %>%
html_text())
date_article
########
########  https://lanationbenin.info/ ############
lanationbenin <- function(start_d, end_d){
# category url collecte
url_category <- read_html("https://lanationbenin.info/")%>%
html_nodes(".tz-header .tz-header-menu nav .menu-menu-principal-container ul li a") %>%
html_attr("href") %>% str_trim()  %>% .[c(2:6,8:13)]
# Collect pagination by rubrique
number_pag <- map_dfr(.x = url_category,
.f = function(x){
tibble(url = x,
nbr_pg=tryCatch(
read_html(x) %>%
html_nodes(".container #content ul li") %>%
html_text() %>% tail(2) %>% head(1) %>% as.integer(),
error = function(e){NA},
warning=  function(e){NA}))})
# Build all url
number_pag <- na.omit(number_pag)
number_pag_order <- number_pag %>%
split(1:nrow(.)) %>%
map_dfr(.f = function(x){
tibble(url = x$url,
nbr_pg=sort(1:x$nbr_pg))})
number_pag_order <- number_pag_order[order(number_pag_order$nbr_pg),]
url_pag_lanationbenin <- paste0(number_pag_order$url,'page/', number_pag_order$nbr_pg, "/")
# Collect article url by pagination
art_lanationbenin <- data.frame()
for(i in 1:length(url_pag_lanationbenin)){
x <- url_pag_lanationbenin[i]
date_article = try(
read_html(x) %>%
html_nodes(".container #content article header time") %>%
html_text() %>% str_trim())
french.months <- c("janvier", "f\\u00e9vrier", "mars", "avril", "mai", "juin",
"juillet", "ao\\u00fbt", "septembre", "octobre", "novembre", "d\\u00e9cembre")
date_article <- stringi::stri_replace_all_fixed(date_article, french.months, month.abb, vectorize_all=FALSE) %>% dmy() %>% date()
if(is.na(tail(date_article, n=1L))){
next()
}else{
d_i <- tibble(
date_article = date_article,
url_article = tryCatch(
read_html(x) %>%
html_nodes(".container #content article header h2 a") %>%
html_attr("href") %>% str_trim(),
error = function(e){NA},
warning=  function(e){NA}),
title_article = tryCatch(
read_html(x) %>%
html_nodes(".container #content article header h2 a") %>%
html_text() %>% str_trim(),
error = function(e){NA},
warning=  function(e){NA}))
art_lanationbenin <- rbind.data.frame(art_lanationbenin, d_i)
if(tail(date_article, n=1L) > as.Date.character(start_d)-2){
width <- options()$width
cat(paste0(rep('>', width), collapse = ''), "\n")
Sys.sleep(.05)
}else{
cat("Done!\n")
break()
}
}
}
# return
return(art_lanationbenin)
}
start_d="2020-11-01"
end_d="2020-11-10"
article <- lanationbenin(start_d, end_d)
View(article)
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
# build site
usethis::use_pkgdown()
pkgdown::build_site()
library(afnews)
devtools::install_github("armelsoubeiga/afnews")
library(afnews)
url_exists("https://armelsoubeiga.github.io/afnews/index.html",non_2xx_return_value = FALSE, quiet = FALSE)
getwd()
#add dependance package
usethis::use_package("httr")
usethis::use_package("xml2")
usethis::use_package("rvest")
usethis::use_package("tidyverse", type = "depends")
usethis::use_package("lubridate")
usethis::use_package("rapportools")
usethis::use_package("stringi")
# build doc
devtools::document()
devtools::check()
# build site
usethis::use_pkgdown()
pkgdown::build_site()
# Créez un PAT GitHub et Créez une clé API Travis
usethis::browse_github_token()
#
# Étape 5: Hébergez le site Web à l'aide de pages GitHub
# ======================================================
# Ajouter _pkgdown.yml à Rbuildignore
usethis::use_build_ignore(files = "_pkgdown.yml")
# Créez un PAT GitHub et Créez une clé API Travis
usethis::browse_github_token()
